# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TsXgLgWD6eLZE5cErtPVO2ihoHnox13d
"""

# langchain-google-genai íŒ¨í‚¤ì§€ ì„¤ì¹˜
# !pip install -q langchain langchain-google-genai langgraph
# word íŒŒì¼ ì½ì–´ì˜¤ê¸° ìœ„í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# !pip install -q python-docx langchain langchain-google-genai langgraph

import streamlit as st
import os
import docx
from typing import TypedDict
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END

# ==========================================
# 1. ê¸°ë³¸ ì„¤ì • & ë¹„ë°€í‚¤ ë¡œë“œ
# ==========================================
st.set_page_config(page_title="AI ì»¤ë¦¬ì–´ ì½”ì¹˜ (ì •ë°€ë¶„ì„)", page_icon="ğŸ¯", layout="wide")

# API í‚¤ ë¡œë“œ (Streamlit Secrets)
if "GOOGLE_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("ğŸš¨ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ëª¨ë¸ ì„¤ì •
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

# ==========================================
# 2. ë¡œì§ í•¨ìˆ˜ (íŒŒì„œ ì‚­ì œë¨ -> ì‹¬í”Œí•´ì§)
# ==========================================

# (1) ì´ë ¥ì„œ íŒŒì¼ ì½ê¸°
def read_resume_file(uploaded_file):
    try:
        doc = docx.Document(uploaded_file)
        full_text = []
        for para in doc.paragraphs:
            if para.text.strip():
                full_text.append(para.text)
        for table in doc.tables:
            for row in table.rows:
                row_text = [cell.text for cell in row.cells if cell.text.strip()]
                if row_text:
                    full_text.append(" | ".join(row_text))
        return "\n".join(full_text)
    except Exception as e:
        return f"ì´ë ¥ì„œ ì½ê¸° ì‹¤íŒ¨: {e}"

# (2) ìƒíƒœ ì •ì˜ (ì´ì œ íŒŒì‹±ëœ ê²°ê³¼ê°€ ì•„ë‹ˆë¼, ì…ë ¥ ìì²´ê°€ ë¶„ë¦¬ë¨)
class AgentState(TypedDict):
    resume_text: str       # ë‚´ ì´ë ¥ì„œ
    duties: str            # ì£¼ìš” ì—…ë¬´
    requirements: str      # ìê²© ìš”ê±´
    preferred: str         # ìš°ëŒ€ ì‚¬í•­
    final_result: str      # ê²°ê³¼

# (3) ë§¤ì¹­ ë…¸ë“œ (ë°”ë¡œ ë¹„êµ ì‹œì‘!)
def match_node(state: AgentState):
    prompt = ChatPromptTemplate.from_template("""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ IT ì±„ìš© ë‹´ë‹¹ìì…ë‹ˆë‹¤.
    ì§€ì›ìì˜ ì´ë ¥ì„œë¥¼ ì±„ìš©ê³µê³ ì˜ 3ëŒ€ ìš”ì†Œì™€ ì •ë°€ ëŒ€ì¡°í•˜ì—¬ í‰ê°€í•˜ì„¸ìš”.

    ---
    [ğŸ“‚ ì§€ì›ì ì´ë ¥ì„œ]
    {resume}

    [ğŸ¢ ëª©í‘œ ì±„ìš©ê³µê³ ]
    1. ğŸ“Œ ì£¼ìš” ì—…ë¬´ (Duties):
    {duties}

    2. âš ï¸ ìê²© ìš”ê±´ (Must-Have):
    {requirements}

    3. ğŸŒŸ ìš°ëŒ€ ì‚¬í•­ (Nice-to-Have):
    {preferred}

    ---
    **ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸:**

    1. ğŸ“Š **ì í•©ë„ ì ìˆ˜**: OOì  / 100ì 
       - (ê°ì  ìš”ì¸ê³¼ ê°€ì‚°ì  ìš”ì¸ì„ ëª…í™•íˆ ê·¼ê±°ë¡œ ì œì‹œ)

    2. âœ… **í•©ê²© í¬ì¸íŠ¸ (Matching)**:
       - ì§€ì›ìê°€ ì™„ë²½í•˜ê²Œ ì¶©ì¡±í•˜ëŠ” ìš”ê±´

    3. ğŸš¨ **ë³´ì™„ í•„ìš” ì‚¬í•­ (Gap Analysis)**:
       - ìê²©ìš”ê±´ ì¤‘ ë¶€ì¡±í•œ ë¶€ë¶„ (ì¹˜ëª…ì )
       - ìš°ëŒ€ì‚¬í•­ ì¤‘ ë†“ì¹œ ë¶€ë¶„ (ê²½ìŸë ¥ ì•½í™”)

    4. ğŸ’¡ **í•„ìŠ¹ ì „ëµ ë° ì¶”ì²œ í”„ë¡œì íŠ¸**:
       - ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë©”ìš°ê¸° ìœ„í•´ [ì–´ë–¤ ê¸°ìˆ ]ì„ ì‚¬ìš©í•˜ì—¬ [ì–´ë–¤ ë¯¸ë‹ˆ í”„ë¡œì íŠ¸]ë¥¼ í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆ.
    """)

    chain = prompt | llm
    response = chain.invoke({
        "resume": state['resume_text'],
        "duties": state['duties'],
        "requirements": state['requirements'],
        "preferred": state['preferred']
    })

    return {"final_result": response.content}

# (4) ê·¸ë˜í”„ ì—°ê²° (íŒŒì„œê°€ ì‚¬ë¼ì ¸ì„œ ì•„ì£¼ ë‹¨ìˆœí•´ì§)
workflow = StateGraph(AgentState)
workflow.add_node("matcher", match_node) # ë…¸ë“œê°€ í•˜ë‚˜ë¿!
workflow.set_entry_point("matcher")      # ë°”ë¡œ ì‹œì‘
workflow.add_edge("matcher", END)        # ë°”ë¡œ ë
app = workflow.compile()

# ==========================================
# 3. UI êµ¬ì„± (ì…ë ¥ì°½ 3ê°œë¡œ ë¶„ë¦¬)
# ==========================================
st.title("ğŸ¯ AI ì·¨ì—… ë¹„ì„œ: ì±„ìš©ê³µê³  ì •ë°€ ë¶„ì„ê¸°")
st.markdown("ì±„ìš©ê³µê³ ë¥¼ í•­ëª©ë³„ë¡œ ë‚˜ëˆ„ì–´ ì…ë ¥í•˜ë©´ AIê°€ ë” ì •í™•í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("1ï¸âƒ£ ë‚´ ì´ë ¥ì„œ (Word)")
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["docx"])

    st.markdown("---")
    st.subheader("2ï¸âƒ£ ì±„ìš©ê³µê³  ì…ë ¥")

    # ì…ë ¥ì°½ 3ê°œ ë°°ì¹˜
    duties_input = st.text_area("ğŸ“Œ ì£¼ìš” ì—…ë¬´ (ë‹´ë‹¹í•  ì¼)", height=100, placeholder="ì˜ˆ: LLM ëª¨ë¸ ì„œë¹™, ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•...")
    req_input = st.text_area("âš ï¸ ìê²© ìš”ê±´ (í•„ìˆ˜)", height=100, placeholder="ì˜ˆ: Python ëŠ¥ìˆ™ì, Docker ì‚¬ìš© ê²½í—˜...")
    pref_input = st.text_area("ğŸŒŸ ìš°ëŒ€ ì‚¬í•­ (ê°€ì‚°ì )", height=100, placeholder="ì˜ˆ: LangChain í”„ë¡œì íŠ¸ ê²½í—˜, ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬...")

    run_btn = st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

with col2:
    st.subheader("3ï¸âƒ£ ë¶„ì„ ê²°ê³¼")
    if run_btn:
        if not uploaded_file:
            st.warning("ì´ë ¥ì„œ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        elif not duties_input and not req_input: # ìµœì†Œí•œ ì—…ë¬´ë‚˜ ìê²©ìš”ê±´ì€ ìˆì–´ì•¼ í•¨
            st.warning("ì£¼ìš” ì—…ë¬´ì™€ ìê²© ìš”ê±´ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì±„ìš© ë‹´ë‹¹ìì˜ ëˆˆìœ¼ë¡œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # íŒŒì¼ ì½ê¸°
                resume_text = read_resume_file(uploaded_file)

                # ê·¸ë˜í”„ ì‹¤í–‰ (ìª¼ê°œì§„ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬)
                result = app.invoke({
                    "resume_text": resume_text,
                    "duties": duties_input,
                    "requirements": req_input,
                    "preferred": pref_input
                })

                # ê²°ê³¼ ì¶œë ¥
                st.markdown(result['final_result'])
                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")